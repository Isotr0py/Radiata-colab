{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Mount Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "!nvidia-smi\n",
        "# !nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DmQthxit9PLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mlbun0yZbmgg",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "#@title Install Radiata and Requirements\n",
        "#@markdown Radiata Install options\n",
        "GoogleDrive_Install = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Requirements options\n",
        "Torch_nightly = False #@param {type:\"boolean\"}\n",
        "xFormers = True #@param {type:\"boolean\"}\n",
        "TensorRT = True #@param {type:\"boolean\"}\n",
        "\n",
        "if GoogleDrive_Install:\n",
        "  %cd /content/gdrive/MyDrive\n",
        "else:\n",
        "  %cd /content/\n",
        "\n",
        "!git clone https://github.com/ddPn08/Radiata.git\n",
        "\n",
        "%cd Radiata\n",
        "if Torch_nightly:\n",
        "  !pip install --pre torch torchvision --force-reinstall \\\n",
        "    --index-url https://download.pytorch.org/whl/nightly/cu118\n",
        "  clear_output()\n",
        "\n",
        "!pip install -q -r requirements/base.txt\n",
        "clear_output()\n",
        "\n",
        "if TensorRT:\n",
        "  !pip install -q -r requirements/tensorrt.txt\n",
        "  !pip install tensorrt\n",
        "  clear_output()\n",
        "\n",
        "if xFormers:\n",
        "  !pip install -U xformers\n",
        "  clear_output()\n",
        "  !python -m xformers.info\n",
        "\n",
        "print(\"ðŸ”„ Requirements Installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztkV2sVumW5K",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Launch Radiata\n",
        "#@markdown Radiata Dictionary\n",
        "Radiata_Dir = '/content/gdrive/MyDrive/Radiata' #@param {type:\"string\"}\n",
        "\n",
        "%cd $Radiata_Dir\n",
        "\n",
        "#@markdown Radiata Version Control\n",
        "Operation = \"Update\" #@param [\"Update\", \"Rollback\", \"Skip\"]\n",
        "Commit_SHA = '' #@param {type:\"string\"}\n",
        "\n",
        "if Operation == \"Rollback\":\n",
        "  %rm -f $Radiata_Dir/.git/index.lock\n",
        "  !git config core.filemode false\n",
        "  !git reset --hard $Commit_SHA\n",
        "  !git pull\n",
        "elif Operation == \"Update\":\n",
        "  %rm -f $Radiata_Dir/.git/index.lock\n",
        "  !git config core.filemode false\n",
        "  !git reset --hard main\n",
        "  !git pull\n",
        "\n",
        "#@markdown Radiata Launch Options\n",
        "xFormers = True #@param {type:\"boolean\"}\n",
        "TensorRT = True #@param {type:\"boolean\"}\n",
        "Deepfloyd_IF = False #@param {type:\"boolean\"}\n",
        "Launch_Mode = \"inline\" #@param [\"inline\", \"gradio\", \"ngrok\"]\n",
        "ngrokToken = \"\" #@param {type:\"string\"}\n",
        "\n",
        "cmd_args = \"--skip-install \"\n",
        "cmd_args += \"--xformers \" if xFormers\n",
        "cmd_args += \"--tensorrt \" if TensorRT\n",
        "cmd_args += \"--deepfloyd_if \" if Deepfloyd_IF\n",
        "\n",
        "\n",
        "def inline_launch():\n",
        "  import modules.ui as ui\n",
        "  import webui\n",
        "\n",
        "  webui.pre_load()\n",
        "  demo = ui.create_ui().queue(64)\n",
        "\n",
        "  demo = demo.launch(\n",
        "    inline=True,\n",
        "    share=True,\n",
        "    prevent_thread_lock=True,\n",
        "    debug=True\n",
        "  )\n",
        "\n",
        "def gradio_launch():\n",
        "  cmd_args += \"--share\"\n",
        "  !COMMANDLINE_ARGS=\"{cmd_args}\" python launch.py\n",
        "\n",
        "def ngrok_launch():\n",
        "  try:\n",
        "    from pyngrok import conf, ngrok\n",
        "  except:\n",
        "    from pyngrok import conf, ngrok\n",
        "    conf.get_default().auth_token = ngrokToken\n",
        "    conf.get_default().monitor_thread = False\n",
        "    ssh_tunnels = ngrok.get_tunnels(conf.get_default())\n",
        "    if len(ssh_tunnels) == 0:\n",
        "        ssh_tunnel = ngrok.connect(7860)\n",
        "        print('addressï¼š'+ssh_tunnel.public_url)\n",
        "    else:\n",
        "        print('addressï¼š'+ssh_tunnels[0].public_url)\n",
        "  cmd_args += \"--share\"\n",
        "  !COMMANDLINE_ARGS=\"{cmd_args}\" python launch.py\n",
        "\n",
        "import os\n",
        "os.environ[\"COMMANDLINE_ARGS\"] = cmd_args\n",
        "os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n",
        "\n",
        "if Launch_Mode == \"inline\":\n",
        "  inline_launch()\n",
        "elif Launch_Mode == \"gradio\":\n",
        "  gradio_launch()\n",
        "elif Launch_Mode == \"ngrok\":\n",
        "  ngrok_launch()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}